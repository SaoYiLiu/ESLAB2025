import cv2
import mediapipe as mp
import time
import os
import sys
import serial
import numpy as np
from picamera2 import Picamera2

# ===================================================
# 0. ç’°å¢ƒå’Œåˆå§‹åŒ–è¨­ç½®
# ===================================================

# åœ–å½¢åŒ–ç’°å¢ƒè¨­å®š
os.environ['QT_QPA_PLATFORM'] = 'xcb' 
WIDTH, HEIGHT = 640, 480
FPS = 30 
TARGET_SIZE = 64  # STM32 æ¨¡å‹è¼¸å…¥å¤§å°

# ---------------------------------------------------
# MediaPipe åˆå§‹åŒ–
# ---------------------------------------------------
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils

# ---------------------------------------------------
# UART åˆå§‹åŒ–
# ---------------------------------------------------
try:
    # ğŸŒŸ ä¿æŒä½¿ç”¨ /dev/serial0 (RPi çš„ç¡¬é«” UART), é®‘ç‡ 115200 bps
    # æ­¤åŸ å°‡é€£æ¥åˆ° STM32 çš„ UART4 (PA0/PA1 æˆ– Arduino D1/D0)
    ser = serial.Serial('/dev/serial0', 115200, timeout=1)
    print("âœ… UART é€£æ¥æˆåŠŸ: /dev/serial0 @ 115200 bps (ç›®æ¨™: STM32 UART4)")
except serial.SerialException as e:
    print(f"âŒ UART é€£æ¥å¤±æ•—: {e}")
    ser = None

# ---------------------------------------------------
# Picamera2 ç›¸æ©Ÿåˆå§‹åŒ–
# ---------------------------------------------------
try:
    picam2 = Picamera2()
    picam2.configure(picam2.create_preview_configuration(
        main={"size": (WIDTH, HEIGHT)}, raw=None, controls={"FrameRate": FPS}
    ))
    picam2.start()
    time.sleep(1)
    print("âœ… Picamera2 æ”å½±æ©Ÿæœå‹™å•Ÿå‹•æˆåŠŸã€‚")
except Exception as e:
    print(f"âŒ Picamera2 å•Ÿå‹•å¤±æ•—ï¼š{e}")
    sys.exit(1)

# ---------------------------------------------------
# OpenCV è¦–çª—åˆå§‹åŒ–
# ---------------------------------------------------
WINDOW_NAME = 'RPi Hand Tracking & Sender'
cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_AUTOSIZE)

# ===================================================
# 1. å½±åƒè™•ç†è¼”åŠ©å‡½å¼ (ä¸è®Š)
# ===================================================

def resize_and_pad_gray(img, target_size):
    """è½‰ç°éšä¸¦ä¿æŒæ¯”ä¾‹ç¸®æ”¾è‡³ target_sizeï¼Œè£œé»‘é‚Š"""
    if len(img.shape) > 2:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
    h, w = img.shape[:2]
    scale = target_size / max(h, w)
    new_w, new_h = int(w * scale), int(h * scale)
    
    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
    canvas = np.zeros((target_size, target_size), dtype=np.uint8)
    
    x_offset = (target_size - new_w) // 2
    y_offset = (target_size - new_h) // 2
    
    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
    return canvas

def send_image_via_uart(processed_img):
    """å°‡ 64x64 å½±åƒè½‰ç‚º Float32 ä¸¦é€é UART ç™¼é€ (16384 bytes)"""
    if ser:
        try:
            float_data = processed_img.astype(np.float32)
            bytes_to_send = float_data.tobytes()
            
            print(f"ğŸš€ [å‚³é€ä¸­] ç™¼é€å½±åƒè³‡æ–™: {len(bytes_to_send)} bytes (Float32)...")
            ser.write(bytes_to_send)
            print("âœ… [å‚³é€å®Œæˆ]")
        except Exception as e:
            print(f"âŒ UART ç™¼é€éŒ¯èª¤: {e}")
    else:
        print("âš ï¸ UART æœªé€£æ¥ï¼Œç„¡æ³•ç™¼é€å½±åƒã€‚")

# ===================================================
# 2. ä¸»è¿´åœˆ
# ===================================================

print("--- ç¨‹å¼é‹è¡Œä¸­ï¼šå…¨ç¨‹é è¦½éª¨æ¶ï¼Œæ¯ 10 ç§’å‚³é€ä¸€æ¬¡è³‡æ–™ ---")
next_capture_time = time.time() + 10.0 
last_sent_preview = None 

try:
    while True:
        # A. æ¯ä¸€å¹€éƒ½åŸ·è¡Œï¼šæŠ“åœ– + MediaPipe åµæ¸¬
        frame_array = picam2.capture_array()
        frame = cv2.cvtColor(frame_array, cv2.COLOR_RGB2BGR)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        results = hands.process(rgb_frame)
        
        bbox = None
        current_hand_crop = None
        
        # ç¹ªè£½éª¨æ¶
        if results.multi_hand_landmarks:
            hand = results.multi_hand_landmarks[0]
            mp_drawing.draw_landmarks(frame, hand, mp_hands.HAND_CONNECTIONS)
            
            # è¨ˆç®— Bounding Box
            h_img, w_img, _ = frame.shape
            xs = [lm.x for lm in hand.landmark]
            ys = [lm.y for lm in hand.landmark]
            
            x_vals = [int(x * w_img) for x in xs]
            y_vals = [int(y * h_img) for y in ys]
            
            box_w = max(x_vals) - min(x_vals)
            box_h = max(y_vals) - min(y_vals)
            
            mx, my = int(box_w * 0.2), int(box_h * 0.2)
            xmin, xmax = max(0, min(x_vals)-mx), min(w_img, max(x_vals)+mx)
            ymin, ymax = max(0, min(y_vals)-my), min(h_img, max(y_vals)+my)
            
            if xmax > xmin and ymax > ymin:
                bbox = (xmin, ymin, xmax, ymax)
                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
                current_hand_crop = frame[ymin:ymax, xmin:xmax]

        # B. æª¢æŸ¥æ™‚é–“ï¼šæ˜¯å¦åˆ°é”å‚³é€æ™‚åˆ» (æ¯ 10 ç§’)
        current_time = time.time()
        
        if current_time >= next_capture_time:
            print(f"\nâ° æ™‚é–“åˆ° ({time.strftime('%H:%M:%S')}) - æº–å‚™å‚³é€...")
            
            if current_hand_crop is not None:
                # åŸ·è¡Œå‰è™•ç†
                processed_img = resize_and_pad_gray(current_hand_crop, TARGET_SIZE)
                
                # æ›´æ–°å·¦ä¸Šè§’çš„é è¦½ç¸®åœ–
                last_sent_preview = cv2.cvtColor(processed_img, cv2.COLOR_GRAY2BGR)
                
                # åŸ·è¡Œ UART å‚³é€
                send_image_via_uart(processed_img)
            else:
                print("âš ï¸ æ™‚é–“åˆ°ä½†æœªåµæ¸¬åˆ°æ‰‹éƒ¨ï¼Œæœ¬æ¬¡è·³éã€‚")
            
            # è¨­å®šä¸‹ä¸€æ¬¡å‚³é€æ™‚é–“
            next_capture_time = current_time + 10.0

        # C. é¡¯ç¤ºè³‡è¨Šèˆ‡ç•«é¢
        remaining = max(0, next_capture_time - current_time)
        cv2.putText(frame, f"Next Send: {remaining:.1f}s", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

        # é¡¯ç¤ºæœ€å¾Œä¸€æ¬¡å‚³é€çš„ç¸®åœ–
        if last_sent_preview is not None:
            frame[0:64, 0:64] = last_sent_preview
            cv2.rectangle(frame, (0,0), (64,64), (0,0,255), 2)
            cv2.putText(frame, "Sent", (0, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)

        cv2.imshow(WINDOW_NAME, frame)
        
        key = cv2.waitKey(1) 
        if key & 0xFF == ord('q'):
            break

except KeyboardInterrupt:
    pass
except Exception as e:
    print(f"ä¸»è¿´åœˆç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")

finally:
    print("\n--- ç¨‹å¼é€€å‡ºä¸­ï¼Œé‡‹æ”¾è³‡æº ---")
    picam2.stop()
    cv2.destroyAllWindows()
    if ser:
        ser.close()
    print("âœ… ç¨‹å¼å·²å®‰å…¨é€€å‡ºã€‚")